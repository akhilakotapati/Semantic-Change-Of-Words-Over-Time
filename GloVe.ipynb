{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint as pp\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "text = pd.read_csv(\"/home/vamsi/Downloads/state-of-the-unionconv.csv\", names=[\"year\", \"speech\"])\n",
    "speech = text.speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Division of Dataset as per decades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = (text.groupby((text.year//10)*10).speech.apply(''.join))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136354"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#some exploring\n",
    "decade = pd.DataFrame(dec)\n",
    "len(decade.speech[1790])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'speech'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decade.columns=['year', 'speech']\n",
    "decade.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = pd.DataFrame(list(range(1790,2020,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "year.columns=[\"Year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([year.Year,decade.speech],ignore_index=True,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some Cleaning..!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1790,2020,10):\n",
    "    decade.speech[i] = decade.speech[i].replace(\"\\n\",\" \")\n",
    "    decade.speech[i] = decade.speech[i].replace(',', ' ')\n",
    "    decade.speech[i] = decade.speech[i].replace('$', '')\n",
    "    decade.speech[i] = decade.speech[i].replace('(', '')\n",
    "    decade.speech[i] = decade.speech[i].replace(')', '')\n",
    "    decade.speech[i] = decade.speech[i].lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dividing and storing the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1790 = decade.speech[1790]\n",
    "data_1800 = decade.speech[1800]\n",
    "data_1810 = decade.speech[1810]\n",
    "data_1820 = decade.speech[1820]\n",
    "data_1830 = decade.speech[1830]\n",
    "data_1840 = decade.speech[1840]\n",
    "data_1850 = decade.speech[1850]\n",
    "data_1860 = decade.speech[1860]\n",
    "data_1870 = decade.speech[1870]\n",
    "data_1880 = decade.speech[1880]\n",
    "data_1890 = decade.speech[1890]\n",
    "data_1900 = decade.speech[1900]\n",
    "data_1910 = decade.speech[1910]\n",
    "data_1920 = decade.speech[1920]\n",
    "data_1930 = decade.speech[1930]\n",
    "data_1940 = decade.speech[1940]\n",
    "data_1950 = decade.speech[1950]\n",
    "data_1960 = decade.speech[1960]\n",
    "data_1970 = decade.speech[1970]\n",
    "data_1980 = decade.speech[1980]\n",
    "data_1990 = decade.speech[1990]\n",
    "data_2000 = decade.speech[2000]\n",
    "data_2010 = decade.speech[2010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Dataset as a whole..!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = []\n",
    "for i in speech:\n",
    "    t.append(i)\n",
    "temp = \"\".join(t)\n",
    "sentences = sent_tokenize(temp)\n",
    "words=[]\n",
    "for i in sentences:\n",
    "    words.append(word_tokenize(i))\n",
    "flattened  = [val for sublist in words for val in sublist]\n",
    "thefile = open('state_union.txt', 'w')\n",
    "for item in flattened:\n",
    "      thefile.write(\"%s \" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['George',\n",
       "  'Washington',\n",
       "  'January',\n",
       "  '8',\n",
       "  ',',\n",
       "  '1790',\n",
       "  'Fellow-Citizens',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Senate',\n",
       "  'and',\n",
       "  'House',\n",
       "  'of',\n",
       "  'Representatives',\n",
       "  ':',\n",
       "  'I',\n",
       "  'embrace',\n",
       "  'with',\n",
       "  'great',\n",
       "  'satisfaction',\n",
       "  'the',\n",
       "  'opportunity',\n",
       "  'which',\n",
       "  'now',\n",
       "  'presents',\n",
       "  'itself',\n",
       "  'of',\n",
       "  'congratulating',\n",
       "  'you',\n",
       "  'on',\n",
       "  'the',\n",
       "  'present',\n",
       "  'favorable',\n",
       "  'prospects',\n",
       "  'of',\n",
       "  'our',\n",
       "  'public',\n",
       "  'affairs',\n",
       "  '.'],\n",
       " ['The',\n",
       "  'recent',\n",
       "  'accession',\n",
       "  'of',\n",
       "  'the',\n",
       "  'important',\n",
       "  'state',\n",
       "  'of',\n",
       "  'North',\n",
       "  'Carolina',\n",
       "  'to',\n",
       "  'the',\n",
       "  'Constitution',\n",
       "  'of',\n",
       "  'the',\n",
       "  'United',\n",
       "  'States',\n",
       "  '(',\n",
       "  'of',\n",
       "  'which',\n",
       "  'official',\n",
       "  'information',\n",
       "  'has',\n",
       "  'been',\n",
       "  'received',\n",
       "  ')',\n",
       "  ',',\n",
       "  'the',\n",
       "  'rising',\n",
       "  'credit',\n",
       "  'and',\n",
       "  'respectability',\n",
       "  'of',\n",
       "  'our',\n",
       "  'country',\n",
       "  ',',\n",
       "  'the',\n",
       "  'general',\n",
       "  'and',\n",
       "  'increasing',\n",
       "  'good',\n",
       "  'will',\n",
       "  'toward',\n",
       "  'the',\n",
       "  'government',\n",
       "  'of',\n",
       "  'the',\n",
       "  'Union',\n",
       "  ',',\n",
       "  'and',\n",
       "  'the',\n",
       "  'concord',\n",
       "  ',',\n",
       "  'peace',\n",
       "  ',',\n",
       "  'and',\n",
       "  'plenty',\n",
       "  'with',\n",
       "  'which',\n",
       "  'we',\n",
       "  'are',\n",
       "  'blessed',\n",
       "  'are',\n",
       "  'circumstances',\n",
       "  'auspicious',\n",
       "  'in',\n",
       "  'an',\n",
       "  'eminent',\n",
       "  'degree',\n",
       "  'to',\n",
       "  'our',\n",
       "  'national',\n",
       "  'prosperity',\n",
       "  '.'],\n",
       " ['In',\n",
       "  'resuming',\n",
       "  'your',\n",
       "  'consultations',\n",
       "  'for',\n",
       "  'the',\n",
       "  'general',\n",
       "  'good',\n",
       "  'you',\n",
       "  'can',\n",
       "  'not',\n",
       "  'but',\n",
       "  'derive',\n",
       "  'encouragement',\n",
       "  'from',\n",
       "  'the',\n",
       "  'reflection',\n",
       "  'that',\n",
       "  'the',\n",
       "  'measures',\n",
       "  'of',\n",
       "  'the',\n",
       "  'last',\n",
       "  'session',\n",
       "  'have',\n",
       "  'been',\n",
       "  'as',\n",
       "  'satisfactory',\n",
       "  'to',\n",
       "  'your',\n",
       "  'constituents',\n",
       "  'as',\n",
       "  'the',\n",
       "  'novelty',\n",
       "  'and',\n",
       "  'difficulty',\n",
       "  'of',\n",
       "  'the',\n",
       "  'work',\n",
       "  'allowed',\n",
       "  'you',\n",
       "  'to',\n",
       "  'hope',\n",
       "  '.'],\n",
       " ['Still',\n",
       "  'further',\n",
       "  'to',\n",
       "  'realize',\n",
       "  'their',\n",
       "  'expectations',\n",
       "  'and',\n",
       "  'to',\n",
       "  'secure',\n",
       "  'the',\n",
       "  'blessings',\n",
       "  'which',\n",
       "  'a',\n",
       "  'gracious',\n",
       "  'Providence',\n",
       "  'has',\n",
       "  'placed',\n",
       "  'within',\n",
       "  'our',\n",
       "  'reach',\n",
       "  'will',\n",
       "  'in',\n",
       "  'the',\n",
       "  'course',\n",
       "  'of',\n",
       "  'the',\n",
       "  'present',\n",
       "  'important',\n",
       "  'session',\n",
       "  'call',\n",
       "  'for',\n",
       "  'the',\n",
       "  'cool',\n",
       "  'and',\n",
       "  'deliberate',\n",
       "  'exertion',\n",
       "  'of',\n",
       "  'your',\n",
       "  'patriotism',\n",
       "  ',',\n",
       "  'firmness',\n",
       "  ',',\n",
       "  'and',\n",
       "  'wisdom',\n",
       "  '.'],\n",
       " ['Among',\n",
       "  'the',\n",
       "  'many',\n",
       "  'interesting',\n",
       "  'objects',\n",
       "  'which',\n",
       "  'will',\n",
       "  'engage',\n",
       "  'your',\n",
       "  'attention',\n",
       "  'that',\n",
       "  'of',\n",
       "  'providing',\n",
       "  'for',\n",
       "  'the',\n",
       "  'common',\n",
       "  'defense',\n",
       "  'will',\n",
       "  'merit',\n",
       "  'particular',\n",
       "  'regard',\n",
       "  '.']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened  = [val for sublist in words for val in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing GloVe for whole data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glove import Glove,Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = Corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#whole data\n",
    "corpus.fit(words,window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = Glove(no_components=100, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = glove.fit(corpus.matrix, epochs=3, no_threads=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove.add_dictionary(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('means', 0.99677929956553601),\n",
       " ('power', 0.99669953221642116),\n",
       " ('most', 0.99641598504891371),\n",
       " ('every', 0.99635886038344512),\n",
       " ('change', 0.99631303577198083),\n",
       " ('good', 0.99610284775731195),\n",
       " ('through', 0.99592575007007655),\n",
       " ('action', 0.99587839663180089),\n",
       " ('another', 0.99576629599543742)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.most_similar('man', number=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12382, 50)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GloVe vectors are being converted to word2vec format for the support of gensim package\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'state_vectors.txt'\n",
    "word2vec_output_file = 'glove_word2vec.txt'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "filename = 'glove_word2vec.txt'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x7f53ab610850>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_words = list(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model[model_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vamsi/.local/lib/python2.7/site-packages/numpy/core/_methods.py:116: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/pairwise.py:248: RuntimeWarning: invalid value encountered in add\n",
      "  distances += XX\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cluster/k_means_.py:400: RuntimeWarning: overflow encountered in square\n",
      "  max_iter=max_iter, verbose=verbose)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cluster/k_means_.py:400: RuntimeWarning: invalid value encountered in subtract\n",
      "  max_iter=max_iter, verbose=verbose)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cluster/k_means_.py:401: RuntimeWarning: overflow encountered in square\n",
      "  inertia = np.sum((X - centers[labels]) ** 2, dtype=np.float64)\n"
     ]
    }
   ],
   "source": [
    "#k-means\n",
    "from sklearn.cluster import KMeans\n",
    "k_value = 20\n",
    "model_k = KMeans(n_clusters=k_value, init='k-means++', max_iter=100, n_init=1)\n",
    "idx = model_k.fit_predict(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# viewing top words in the clusters\n",
    "index2word =[]\n",
    "for i in range(0,len(model_words)):\n",
    "     index2word.append(model_words[i])\n",
    "                                                                                           \n",
    "word_centroid_map = dict(zip(index2word, idx))\n",
    "\n",
    "# For the first 10 clusters\n",
    "for cluster in range(0,20):\n",
    "    \n",
    "    # Print the cluster number  \n",
    "    print(\"\\nCluster %d\" % cluster)\n",
    "    \n",
    "#     # Find all of the words for that cluster number, and print them out\n",
    "wordi = []\n",
    "    for i in range(0,len(word_centroid_map)):\n",
    "        if( word_centroid_map[list(word_centroid_map)[i]] == cluster ):\n",
    "             wordi.append(list(word_centroid_map)[i])\n",
    "print(wordi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models per Decade..!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 15 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('for', 0.99881909861428497),\n",
       " ('other', 0.99880012425917442),\n",
       " ('peace', 0.9987556209865559),\n",
       " ('senate', 0.99872040909401061),\n",
       " ('laws', 0.99871794916565548),\n",
       " ('part', 0.99870505410814003),\n",
       " ('state', 0.99865832908605379),\n",
       " ('treaty', 0.99854822508591978),\n",
       " ('on', 0.99853915456448294)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 1790\n",
    "#tokenizing to list of lists\n",
    "sentences_1790 = sent_tokenize(data_1790)\n",
    "words_1790=[]\n",
    "for i in sentences_1790:\n",
    "    words_1790.append(word_tokenize(i))\n",
    "    \n",
    "#corpus fitting\n",
    "corpus_1790 = Corpus()\n",
    "corpus_1790.fit(words_1790,window=10)\n",
    "glove_1790 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1790.fit(corpus_1790.matrix, epochs=15, no_threads=4, verbose=True)\n",
    "\n",
    "#adding dictionary with the corpus\n",
    "glove_1790.add_dictionary(corpus_1790.dictionary)\n",
    "\n",
    "#most similar words\n",
    "glove_1790.most_similar('government', number=10)\n",
    "\n",
    "#writing a text file\n",
    "#flattened  = [val for sublist in words_1790 for val in sublist]\n",
    "#thefile = open('state_union_1790.txt', 'w')\n",
    "#for item in flattened:\n",
    " #     thefile.write(\"%s \" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#frequnecy of words over time\n",
    "flattened  = [val for sublist in words_1790 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996758376861\n",
      "-0.968804962419\n"
     ]
    }
   ],
   "source": [
    "#similarity measure calc\n",
    "people = glove_1790.word_vectors[glove_1790.dictionary[\"people\"]]\n",
    "government = glove_1790.word_vectors[glove_1790.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1790.word_vectors[glove_1790.dictionary[\"congress\"]]\n",
    "econ = glove_1790.word_vectors[glove_1790.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 1800\n",
    "sentences_1800 = sent_tokenize(data_1800)\n",
    "words_1800=[]\n",
    "for i in sentences_1800:\n",
    "    words_1800.append(word_tokenize(i))\n",
    "corpus_1800 = Corpus()\n",
    "corpus_1800.fit(words_1800,window=10)\n",
    "glove_1800 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1800.fit(corpus_1800.matrix, epochs=15, no_threads=4, verbose=True)\n",
    "glove_1800.add_dictionary(corpus_1800.dictionary)\n",
    "glove_1800.most_similar('government', number=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('secretary', 0.94355416820997107),\n",
       " ('the', 0.94334971672510837),\n",
       " ('necessity', 0.94280462599491566),\n",
       " ('last', 0.94182582320790642),\n",
       " ('authority', 0.94105905436555348),\n",
       " ('receipts', 0.94089962614429512),\n",
       " ('of', 0.94044853166907361),\n",
       " ('first', 0.94003620710644753),\n",
       " ('treasury', 0.93975566880708217)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_1800.most_similar('people', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.932001037223\n",
      "-0.9588945417\n"
     ]
    }
   ],
   "source": [
    "#similarity measure calc\n",
    "people = glove_1800.word_vectors[glove_1800.dictionary[\"people\"]]\n",
    "government = glove_1800.word_vectors[glove_1800.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1800.word_vectors[glove_1800.dictionary[\"congress\"]]\n",
    "econ = glove_1800.word_vectors[glove_1800.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1800 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 15 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('war', 0.99901339023222191),\n",
       " ('on', 0.99885222803761953),\n",
       " ('at', 0.99870531769200555),\n",
       " ('other', 0.99868522344730792),\n",
       " ('from', 0.99867708465005445),\n",
       " ('all', 0.99858742664701416),\n",
       " ('state', 0.99836886064142893),\n",
       " ('effect', 0.99815526142674005),\n",
       " ('treaty', 0.99811287391314785)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 1810\n",
    "sentences_1810 = sent_tokenize(data_1810)\n",
    "words_1810=[]\n",
    "for i in sentences_1810:\n",
    "    words_1810.append(word_tokenize(i))\n",
    "corpus_1810 = Corpus()\n",
    "corpus_1810.fit(words_1810,window=10)\n",
    "glove_1810 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1810.fit(corpus_1810.matrix, epochs=15, no_threads=4, verbose=True)\n",
    "glove_1810.add_dictionary(corpus_1810.dictionary)\n",
    "glove_1810.most_similar('government', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1810 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99620220339\n",
      "-0.983500907965\n"
     ]
    }
   ],
   "source": [
    "people = glove_1810.word_vectors[glove_1810.dictionary[\"people\"]]\n",
    "government = glove_1810.word_vectors[glove_1810.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1810.word_vectors[glove_1810.dictionary[\"congress\"]]\n",
    "econ = glove_1810.word_vectors[glove_1810.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('upon', 0.99847990284321286),\n",
       " ('governments', 0.99838545478824459),\n",
       " ('department', 0.9981942800316016),\n",
       " ('interest', 0.99811457658674452),\n",
       " ('protection', 0.99794749538919503),\n",
       " ('at', 0.99783370675661009),\n",
       " ('duties', 0.99781277949684799),\n",
       " ('parties', 0.99776080953864532),\n",
       " ('laws', 0.99773771001791678)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 1820\n",
    "sentences_1820 = sent_tokenize(data_1820)\n",
    "words_1820=[]\n",
    "for i in sentences_1820:\n",
    "    words_1820.append(word_tokenize(i))\n",
    "corpus_1820 = Corpus()\n",
    "corpus_1820.fit(words_1820,window=10)\n",
    "glove_1820 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1820.fit(corpus_1820.matrix, epochs=10, no_threads=4, verbose=True)\n",
    "glove_1820.add_dictionary(corpus_1820.dictionary)\n",
    "glove_1820.most_similar('people', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997423045499\n",
      "0.702341014535\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "people = glove_1820.word_vectors[glove_1820.dictionary[\"people\"]]\n",
    "government = glove_1820.word_vectors[glove_1820.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1820.word_vectors[glove_1820.dictionary[\"congress\"]]\n",
    "econ = glove_1820.word_vectors[glove_1820.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1820 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 1830\n",
    "sentences_1830 = sent_tokenize(data_1830)\n",
    "words_1830=[]\n",
    "for i in sentences_1830:\n",
    "    words_1830.append(word_tokenize(i))\n",
    "corpus_1830 = Corpus()\n",
    "corpus_1830.fit(words_1830,window=10)\n",
    "glove_1830 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1830.fit(corpus_1830.matrix, epochs=15, no_threads=4, verbose=True)\n",
    "glove_1830.add_dictionary(corpus_1830.dictionary)\n",
    "glove_1830.most_similar('government', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96979384303243987"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "people = glove_1830.word_vectors[glove_1830.dictionary[\"people\"]]\n",
    "government = glove_1830.word_vectors[glove_1830.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1830.word_vectors[glove_1830.dictionary[\"congress\"]]\n",
    "econ = glove_1830.word_vectors[glove_1830.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561\n",
      "0\n",
      "202\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1830 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 1840\n",
    "sentences_1840 = sent_tokenize(data_1840)\n",
    "words_1840=[]\n",
    "for i in sentences_1840:\n",
    "    words_1840.append(word_tokenize(i))\n",
    "corpus_1840 = Corpus()\n",
    "corpus_1840.fit(words_1840,window=10)\n",
    "glove_1840 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1840.fit(corpus_1840.matrix, epochs=10, no_threads=4, verbose=True)\n",
    "glove_1840.add_dictionary(corpus_1840.dictionary)\n",
    "glove_1840.most_similar('government', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96668393838708444"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "people = glove_1840.word_vectors[glove_1840.dictionary[\"people\"]]\n",
    "government = glove_1840.word_vectors[glove_1840.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1840.word_vectors[glove_1840.dictionary[\"congress\"]]\n",
    "econ = glove_1840.word_vectors[glove_1840.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633\n",
      "243\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1840 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('department', 0.99774976605884125),\n",
       " ('public', 0.99770233070182579),\n",
       " ('rights', 0.99762774915632035),\n",
       " ('interests', 0.99725579593423608),\n",
       " ('union', 0.99722213871961163),\n",
       " ('several', 0.99715137518877095),\n",
       " ('territories', 0.99701557640434646),\n",
       " ('revenue', 0.99663372203178913),\n",
       " ('powers', 0.99648171580939959)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 1850\n",
    "sentences_1850 = sent_tokenize(data_1850)\n",
    "words_1850=[]\n",
    "for i in sentences_1850:\n",
    "    words_1850.append(word_tokenize(i))\n",
    "corpus_1850 = Corpus()\n",
    "corpus_1850.fit(words_1850,window=10)\n",
    "glove_1850 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1850.fit(corpus_1850.matrix, epochs=10, no_threads=4, verbose=True)\n",
    "glove_1850.add_dictionary(corpus_1850.dictionary)\n",
    "glove_1850.most_similar('people', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93201678054419834"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "people = glove_1850.word_vectors[glove_1850.dictionary[\"people\"]]\n",
    "government = glove_1850.word_vectors[glove_1850.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1850.word_vectors[glove_1850.dictionary[\"congress\"]]\n",
    "econ = glove_1850.word_vectors[glove_1850.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "171\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1850 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 1860\n",
    "sentences_1860 = sent_tokenize(data_1860)\n",
    "words_1860=[]\n",
    "for i in sentences_1860:\n",
    "    words_1860.append(word_tokenize(i))\n",
    "corpus_1860 = Corpus()\n",
    "corpus_1860.fit(words_1860,window=10)\n",
    "glove_1860 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1860.fit(corpus_1860.matrix, epochs=10, no_threads=4, verbose=True)\n",
    "glove_1860.add_dictionary(corpus_1860.dictionary)\n",
    "glove_1860.most_similar('government', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99041437954683764"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "people = glove_1860.word_vectors[glove_1860.dictionary[\"people\"]]\n",
    "government = glove_1860.word_vectors[glove_1860.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1860.word_vectors[glove_1860.dictionary[\"congress\"]]\n",
    "econ = glove_1860.word_vectors[glove_1860.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392\n",
      "246\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1860 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('on', 0.9985962776931756),\n",
       " ('interest', 0.9984283204625406),\n",
       " ('most', 0.99838352492446114),\n",
       " ('laws', 0.99826100740901658),\n",
       " ('territory', 0.99801708191345107),\n",
       " ('value', 0.99800411460073346),\n",
       " ('national', 0.99797421453350998),\n",
       " ('duties', 0.99795797971524403),\n",
       " ('state', 0.99794178018984681)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 1870\n",
    "sentences_1870 = sent_tokenize(data_1870)\n",
    "words_1870=[]\n",
    "for i in sentences_1870:\n",
    "    words_1870.append(word_tokenize(i))\n",
    "corpus_1870 = Corpus()\n",
    "corpus_1870.fit(words_1870,window=10)\n",
    "glove_1870 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1870.fit(corpus_1870.matrix, epochs=10, no_threads=4, verbose=True)\n",
    "glove_1870.add_dictionary(corpus_1870.dictionary)\n",
    "glove_1870.most_similar('people', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99400967893830183"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "people = glove_1870.word_vectors[glove_1870.dictionary[\"people\"]]\n",
    "government = glove_1870.word_vectors[glove_1870.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1870.word_vectors[glove_1870.dictionary[\"congress\"]]\n",
    "econ = glove_1870.word_vectors[glove_1870.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1870 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('law', 0.99836625269090562),\n",
       " ('laws', 0.99833122462906754),\n",
       " ('one', 0.99804826443709416),\n",
       " ('system', 0.99791207275191329),\n",
       " ('from', 0.9978905698244025),\n",
       " ('relations', 0.99772313298344961),\n",
       " ('vessels', 0.99769525549464189),\n",
       " ('service', 0.99755297805863841),\n",
       " ('countries', 0.99752247661896254)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 1880\n",
    "sentences_1880 = sent_tokenize(data_1880)\n",
    "words_1880=[]\n",
    "for i in sentences_1880:\n",
    "    words_1880.append(word_tokenize(i))\n",
    "corpus_1880 = Corpus()\n",
    "corpus_1880.fit(words_1880,window=10)\n",
    "glove_1880 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1880.fit(corpus_1880.matrix, epochs=10, no_threads=4, verbose=True)\n",
    "glove_1880.add_dictionary(corpus_1880.dictionary)\n",
    "glove_1880.most_similar('people', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98644644730136888"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "people = glove_1880.word_vectors[glove_1880.dictionary[\"people\"]]\n",
    "government = glove_1880.word_vectors[glove_1880.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1880.word_vectors[glove_1880.dictionary[\"congress\"]]\n",
    "econ = glove_1880.word_vectors[glove_1880.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505\n",
      "217\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1880 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('foreign', 0.99776829681529411),\n",
       " ('gold', 0.99751832631168857),\n",
       " ('spain', 0.9967690908766903),\n",
       " ('his', 0.99611554215912201),\n",
       " ('relations', 0.99604069700701148),\n",
       " ('reserve', 0.99572770725938187),\n",
       " ('great', 0.99542717076645193),\n",
       " ('home', 0.99515202774512623),\n",
       " ('order', 0.99468545237431372)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 1890\n",
    "sentences_1890 = sent_tokenize(data_1890)\n",
    "words_1890=[]\n",
    "for i in sentences_1890:\n",
    "    words_1890.append(word_tokenize(i))\n",
    "corpus_1890 = Corpus()\n",
    "corpus_1890.fit(words_1890,window=10)\n",
    "glove_1890 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1890.fit(corpus_1890.matrix, epochs=10, no_threads=4, verbose=True)\n",
    "glove_1890.add_dictionary(corpus_1890.dictionary)\n",
    "glove_1890.most_similar('military', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97780945128742847"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "people = glove_1890.word_vectors[glove_1890.dictionary[\"people\"]]\n",
    "government = glove_1890.word_vectors[glove_1890.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1890.word_vectors[glove_1890.dictionary[\"congress\"]]\n",
    "econ = glove_1890.word_vectors[glove_1890.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "734\n",
      "226\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('reserving', 0.98029823935593641),\n",
       " ('cultivated', 0.97910185031557606),\n",
       " ('refuge', 0.97904775579987957),\n",
       " ('relinquish', 0.97881932511775838),\n",
       " ('rationally', 0.9785773676019236),\n",
       " ('525', 0.97849020000651465),\n",
       " ('966', 0.97828473799474813),\n",
       " ('couplers', 0.97817279309056049),\n",
       " ('1869', 0.97816829485110512)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1890 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))\n",
    "glove_1890.most_similar('terror', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 8 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('from', 0.99707110928853793),\n",
       " ('law', 0.99645622899736286),\n",
       " ('upon', 0.9964454843397299),\n",
       " ('under', 0.99615346717861186),\n",
       " ('country', 0.99536374039202613),\n",
       " ('end', 0.99495683966152471),\n",
       " ('on', 0.99495272871208074),\n",
       " ('work', 0.99484325189532163),\n",
       " ('time', 0.99433552523929225)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 1900\n",
    "sentences_1900 = sent_tokenize(data_1900)\n",
    "words_1900=[]\n",
    "for i in sentences_1900:\n",
    "    words_1900.append(word_tokenize(i))\n",
    "corpus_1900 = Corpus()\n",
    "corpus_1900.fit(words_1900,window=10)\n",
    "glove_1900 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1900.fit(corpus_1900.matrix, epochs=8, no_threads=4, verbose=True)\n",
    "glove_1900.add_dictionary(corpus_1900.dictionary)\n",
    "glove_1900.most_similar('government', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98360953695994002"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "people = glove_1900.word_vectors[glove_1900.dictionary[\"people\"]]\n",
    "government = glove_1900.word_vectors[glove_1900.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1900.word_vectors[glove_1900.dictionary[\"congress\"]]\n",
    "econ = glove_1900.word_vectors[glove_1900.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693\n",
      "393\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1900 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('country', 0.99895105649686589),\n",
       " ('law', 0.99777858748930681),\n",
       " ('nation', 0.99774965690083972),\n",
       " ('duty', 0.9975220910167687),\n",
       " ('other', 0.99745846140350403),\n",
       " ('war', 0.99732820111262777),\n",
       " ('from', 0.99716800323219834),\n",
       " ('great', 0.99712041627473613),\n",
       " ('his', 0.99702874759039883)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 1910\n",
    "sentences_1910 = sent_tokenize(data_1910)\n",
    "words_1910=[]\n",
    "for i in sentences_1910:\n",
    "    words_1910.append(word_tokenize(i))\n",
    "corpus_1910 = Corpus()\n",
    "corpus_1910.fit(words_1910,window=10)\n",
    "glove_1910 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1910.fit(corpus_1910.matrix, epochs=10, no_threads=4, verbose=True)\n",
    "glove_1910.add_dictionary(corpus_1910.dictionary)\n",
    "glove_1910.most_similar('government', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99331335242727958"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "people = glove_1910.word_vectors[glove_1910.dictionary[\"people\"]]\n",
    "government = glove_1910.word_vectors[glove_1910.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1910.word_vectors[glove_1910.dictionary[\"congress\"]]\n",
    "econ = glove_1910.word_vectors[glove_1910.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "349\n",
      "135\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1910 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('on', 0.99834381161741992),\n",
       " ('time', 0.99819401368281424),\n",
       " ('from', 0.9981665047641799),\n",
       " ('under', 0.99811823580544756),\n",
       " ('by', 0.9974867686274107),\n",
       " ('work', 0.99738649157730497),\n",
       " ('at', 0.99737540579792072),\n",
       " ('law', 0.99732415593361512),\n",
       " ('national', 0.99724378479669584)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 1920\n",
    "sentences_1920 = sent_tokenize(data_1920)\n",
    "words_1920=[]\n",
    "for i in sentences_1920:\n",
    "    words_1920.append(word_tokenize(i))\n",
    "corpus_1920 = Corpus()\n",
    "corpus_1920.fit(words_1920,window=10)\n",
    "glove_1920 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1920.fit(corpus_1920.matrix, epochs=10, no_threads=4, verbose=True)\n",
    "glove_1920.add_dictionary(corpus_1920.dictionary)\n",
    "glove_1920.most_similar('government', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99485288764502455"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "people = glove_1920.word_vectors[glove_1920.dictionary[\"people\"]]\n",
    "government = glove_1920.word_vectors[glove_1920.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1920.word_vectors[glove_1920.dictionary[\"congress\"]]\n",
    "econ = glove_1920.word_vectors[glove_1920.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "157\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1920 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('.', 0.99935341733904437),\n",
       " ('federal', 0.99919966190853504),\n",
       " ('people', 0.99909418410398909),\n",
       " ('world', 0.99907727617693032),\n",
       " ('nation', 0.99898780074857929),\n",
       " ('national', 0.99898078607020802),\n",
       " ('of', 0.99898054210675313),\n",
       " ('many', 0.99890191556053076),\n",
       " ('for', 0.99889827630812389)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 1930\n",
    "sentences_1930 = sent_tokenize(data_1930)\n",
    "words_1930=[]\n",
    "for i in sentences_1930:\n",
    "    words_1930.append(word_tokenize(i))\n",
    "corpus_1930 = Corpus()\n",
    "corpus_1930.fit(words_1930,window=10)\n",
    "glove_1930 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1930.fit(corpus_1930.matrix, epochs=10, no_threads=4, verbose=True)\n",
    "glove_1930.add_dictionary(corpus_1930.dictionary)\n",
    "glove_1930.most_similar('government', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99909418410398942"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "people = glove_1930.word_vectors[glove_1930.dictionary[\"people\"]]\n",
    "government = glove_1930.word_vectors[glove_1930.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1930.word_vectors[glove_1930.dictionary[\"congress\"]]\n",
    "econ = glove_1930.word_vectors[glove_1930.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1930 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('from', 0.99861246125846781),\n",
       " ('years', 0.99818171158835833),\n",
       " ('on', 0.99807423705690201),\n",
       " ('future', 0.9979807879119742),\n",
       " ('world', 0.99791454805088986),\n",
       " (\"'s\", 0.99787606907247262),\n",
       " ('american', 0.99783326596782107),\n",
       " ('after', 0.99779624026154667),\n",
       " ('through', 0.99775607267693445)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 1940\n",
    "sentences_1940 = sent_tokenize(data_1940)\n",
    "words_1940=[]\n",
    "for i in sentences_1940:\n",
    "    words_1940.append(word_tokenize(i))\n",
    "corpus_1940 = Corpus()\n",
    "corpus_1940.fit(words_1940,window=10)\n",
    "glove_1940 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1940.fit(corpus_1940.matrix, epochs=10, no_threads=4, verbose=True)\n",
    "glove_1940.add_dictionary(corpus_1940.dictionary)\n",
    "glove_1940.most_similar('government', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9974199930467974"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "people = glove_1940.word_vectors[glove_1940.dictionary[\"people\"]]\n",
    "government = glove_1940.word_vectors[glove_1940.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1940.word_vectors[glove_1940.dictionary[\"congress\"]]\n",
    "econ = glove_1940.word_vectors[glove_1940.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217\n",
      "170\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1940 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('federal', 0.99920915669355204),\n",
       " ('for', 0.99843933613029379),\n",
       " ('new', 0.99840632622835546),\n",
       " ('on', 0.99816643514418879),\n",
       " ('great', 0.9981384446296524),\n",
       " ('freedom', 0.99809972033416006),\n",
       " ('defense', 0.99801555655469365),\n",
       " ('use', 0.99795155091578358),\n",
       " ('responsibility', 0.99793390063222853)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 1950\n",
    "sentences_1950 = sent_tokenize(data_1950)\n",
    "words_1950=[]\n",
    "for i in sentences_1950:\n",
    "    words_1950.append(word_tokenize(i))\n",
    "corpus_1950 = Corpus()\n",
    "corpus_1950.fit(words_1950,window=10)\n",
    "glove_1950 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1950.fit(corpus_1950.matrix, epochs=10, no_threads=4, verbose=True)\n",
    "glove_1950.add_dictionary(corpus_1950.dictionary)\n",
    "glove_1950.most_similar('government', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99771110984872513"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "people = glove_1950.word_vectors[glove_1950.dictionary[\"people\"]]\n",
    "government = glove_1950.word_vectors[glove_1950.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1950.word_vectors[glove_1950.dictionary[\"congress\"]]\n",
    "econ = glove_1950.word_vectors[glove_1950.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n",
      "212\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1950 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('or', 0.99882494198429184),\n",
       " ('for', 0.99880504702384965),\n",
       " ('from', 0.99875370615122683),\n",
       " ('time', 0.99860899448642404),\n",
       " (';', 0.99859780963996669),\n",
       " ('peace', 0.99855723609663383),\n",
       " ('with', 0.99846651790834162),\n",
       " ('national', 0.99846580722823264),\n",
       " ('progress', 0.99842025983147165)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 1960\n",
    "sentences_1960 = sent_tokenize(data_1960)\n",
    "words_1960=[]\n",
    "for i in sentences_1960:\n",
    "    words_1960.append(word_tokenize(i))\n",
    "corpus_1960 = Corpus()\n",
    "corpus_1960.fit(words_1960,window=10)\n",
    "glove_1960 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1960.fit(corpus_1960.matrix, epochs=10, no_threads=4, verbose=True)\n",
    "glove_1960.add_dictionary(corpus_1960.dictionary)\n",
    "glove_1960.most_similar('government', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99836960290443533"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "people = glove_1960.word_vectors[glove_1960.dictionary[\"people\"]]\n",
    "government = glove_1960.word_vectors[glove_1960.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1960.word_vectors[glove_1960.dictionary[\"congress\"]]\n",
    "econ = glove_1960.word_vectors[glove_1960.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "154\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1960 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('.', 0.99893987148609575),\n",
       " ('by', 0.99888061049752364),\n",
       " ('peace', 0.99880466781718935),\n",
       " ('federal', 0.99878264149580054),\n",
       " ('on', 0.99872565591456575),\n",
       " ('in', 0.99861672054186168),\n",
       " ('for', 0.99861221942414669),\n",
       " ('with', 0.99859422129576769),\n",
       " ('all', 0.9985692150857205)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 1970\n",
    "sentences_1970 = sent_tokenize(data_1970)\n",
    "words_1970=[]\n",
    "for i in sentences_1970:\n",
    "    words_1970.append(word_tokenize(i))\n",
    "corpus_1970 = Corpus()\n",
    "corpus_1970.fit(words_1970,window=10)\n",
    "glove_1970 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1970.fit(corpus_1970.matrix, epochs=10, no_threads=4, verbose=True)\n",
    "glove_1970.add_dictionary(corpus_1970.dictionary)\n",
    "glove_1970.most_similar('government', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99823546457968937"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "people = glove_1970.word_vectors[glove_1970.dictionary[\"people\"]]\n",
    "government = glove_1970.word_vectors[glove_1970.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1970.word_vectors[glove_1970.dictionary[\"congress\"]]\n",
    "econ = glove_1970.word_vectors[glove_1970.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1970 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 10 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('federal', 0.99860737378759457),\n",
       " ('on', 0.99859992836786704),\n",
       " ('from', 0.99851680980447721),\n",
       " ('system', 0.9983524284199119),\n",
       " ('budget', 0.99828409472315938),\n",
       " ('by', 0.99818414524878885),\n",
       " ('spending', 0.99816987230543308),\n",
       " ('future', 0.99793941517629836),\n",
       " ('use', 0.99788198699234498)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 1980\n",
    "sentences_1980 = sent_tokenize(data_1980)\n",
    "words_1980=[]\n",
    "for i in sentences_1980:\n",
    "    words_1980.append(word_tokenize(i))\n",
    "corpus_1980 = Corpus()\n",
    "corpus_1980.fit(words_1980,window=10)\n",
    "glove_1980 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1980.fit(corpus_1980.matrix, epochs=10, no_threads=4, verbose=True)\n",
    "glove_1980.add_dictionary(corpus_1980.dictionary)\n",
    "glove_1980.most_similar('government', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99751904986739293"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people = glove_1980.word_vectors[glove_1980.dictionary[\"people\"]]\n",
    "government = glove_1980.word_vectors[glove_1980.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1980.word_vectors[glove_1980.dictionary[\"congress\"]]\n",
    "econ = glove_1980.word_vectors[glove_1980.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n",
      "195\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1980 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 1990\n",
    "sentences_1990 = sent_tokenize(data_1990)\n",
    "words_1990=[]\n",
    "for i in sentences_1990:\n",
    "    words_1990.append(word_tokenize(i))\n",
    "corpus_1990 = Corpus()\n",
    "corpus_1990.fit(words_1990,window=10)\n",
    "glove_1990 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_1990.fit(corpus_1990.matrix, epochs=10, no_threads=4, verbose=True)\n",
    "glove_1990.add_dictionary(corpus_1990.dictionary)\n",
    "glove_1990.most_similar('government', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99626221445938412"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people = glove_1990.word_vectors[glove_1990.dictionary[\"people\"]]\n",
    "government = glove_1990.word_vectors[glove_1990.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_1990.word_vectors[glove_1990.dictionary[\"congress\"]]\n",
    "econ = glove_1990.word_vectors[glove_1990.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n",
      "351\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_1990 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 2000\n",
    "sentences_2000 = sent_tokenize(data_2000)\n",
    "words_2000=[]\n",
    "for i in sentences_2000:\n",
    "    words_2000.append(word_tokenize(i))\n",
    "corpus_2000 = Corpus()\n",
    "corpus_2000.fit(words_2000,window=10)\n",
    "glove_2000 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_2000.fit(corpus_2000.matrix, epochs=20, no_threads=4, verbose=True)\n",
    "glove_2000.add_dictionary(corpus_2000.dictionary)\n",
    "glove_2000.most_similar('government', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96744196748818112"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people = glove_2000.word_vectors[glove_2000.dictionary[\"people\"]]\n",
    "government = glove_2000.word_vectors[glove_2000.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_2000.word_vectors[glove_2000.dictionary[\"congress\"]]\n",
    "econ = glove_2000.word_vectors[glove_2000.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "224\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_2000 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 30 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('enduring', 0.98291227634515177),\n",
       " ('red', 0.98191596413319893),\n",
       " ('fiscal', 0.98168932198672687),\n",
       " ('philosophical', 0.9809965576762002),\n",
       " ('surpass', 0.98055603188547391),\n",
       " ('choices', 0.98033264983658419),\n",
       " ('struggling', 0.97979097988524511),\n",
       " ('behavior', 0.97968798421704351),\n",
       " ('30', 0.97967014713108447)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model 2010\n",
    "sentences_2010 = sent_tokenize(data_2010)\n",
    "words_2010=[]\n",
    "for i in sentences_2010:\n",
    "    words_2010.append(word_tokenize(i))\n",
    "corpus_2010 = Corpus()\n",
    "corpus_2010.fit(words_2010,window=10)\n",
    "glove_2010 = Glove(no_components=100, learning_rate=0.05)\n",
    "glove_2010.fit(corpus_2010.matrix, epochs=30, no_threads=4, verbose=True)\n",
    "glove_2010.add_dictionary(corpus_2010.dictionary)\n",
    "#glove_2010.most_similar('people', number=10)\n",
    "glove_2010.most_similar('white', number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98960359101995432"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "people = glove_2010.word_vectors[glove_2010.dictionary[\"people\"]]\n",
    "government = glove_2010.word_vectors[glove_2010.dictionary[\"government\"]]\n",
    "sim = numpy.dot(people,government)/(numpy.linalg.norm(people)*numpy.linalg.norm(government))\n",
    "print(sim)\n",
    "congress = glove_2010.word_vectors[glove_2010.dictionary[\"congress\"]]\n",
    "econ = glove_2010.word_vectors[glove_2010.dictionary[\"economy\"]]\n",
    "sim2 = numpy.dot(econ,congress)/(numpy.linalg.norm(econ)*numpy.linalg.norm(congress))\n",
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "89\n"
     ]
    }
   ],
   "source": [
    "flattened  = [val for sublist in words_2010 for val in sublist]\n",
    "print(flattened.count('government'))\n",
    "print(flattened.count('people'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the models are ran with a learning rate of 0.5 and the epochs(no.of cycles) vary as the sizes of the dataset tend to vary a little. Multiple runs are made to optimise these epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE plots for all the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below gives a plot of word vectors in speeches from 2010-present. (utilises TSNE package)\n",
    "\n",
    "(The same code has been used by altering the source and destination file names to create an image fo each sub divided dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pylab as plot\n",
    "matrix = np.loadtxt(\"/Users/vamsi/Desktop/584 DEcades/state_vectors_2010.txt\", usecols=range(1,49))\n",
    "words = list(np.loadtxt(\"/Users/vamsi/Desktop/584 DEcades/state_vectors_2010.txt\", usecols=[0],dtype=str))\n",
    "\n",
    "#most common 1000 words\n",
    "target_words = [line.strip().lower() for line in open(\"/Users/vamsi/Desktop/common_words.csv\")][:1000]\n",
    "rows = [words.index(word) for word in target_words if word in words]\n",
    "target_matrix = matrix[rows,:]\n",
    "\n",
    "#tsne reduction\n",
    "from sklearn.manifold import TSNE as tsne\n",
    "reduced_matrix = tsne(target_matrix, 2);\n",
    "\n",
    "#Viz\n",
    "plot.figure(figsize=(200, 200), dpi=100)\n",
    "maxi_x = np.amax(reduced_matrix.n_components[0], axis=0)\n",
    "maxi_y = np.amax(reduced_matrix.n_components[1], axis=0)\n",
    "plot.xlim((-maxi_x,maxi_x))\n",
    "plot.ylim((-maxi_y,maxi_y))\n",
    "\n",
    "plot.scatter(reduced_matrix.n_components[:, 0], reduced_matrix.n_components[:, 1], 20);\n",
    "\n",
    "for row_id in range(0, len(rows)):\n",
    "    target_word = words[rows[row_id]]\n",
    "    x = reduced_matrix.n_components[row_id, 0]\n",
    "    y = reduced_matrix.n_components[row_id, 1]\n",
    "    plot.annotate(target_word, (x,y))\n",
    "    \n",
    "\n",
    "\n",
    "plot.savefig(\"/Users/vamsi/Desktop/584 DEcades/images/2010.png\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A package called 'glove_python' (which is a toy implementation of GloVe in python) is used in the beginning to calculate the most similar words and the similarity between selected word pairs.\n",
    "\n",
    "**This package doesn't run in a mac or windows as a gcc compiler is needed to compile the package setup file. (works on Unix, or need to change the compiler from clang++ to gcc++ and explicitly export the default flags to run on gcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual vector embeddings that are represented using TSNE have been generated using the open source C files available in GITHUB @(https://github.com/stanfordnlp/GloVe)\n",
    "\n",
    "The text files generated per each model consists of the word along with its vector. These are generated by modifying the code from the above link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*No pre-trained vectors have been used. All the models are trained on new corpus using the above stated C files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
